{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will: \n",
    "\n",
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m841.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (391 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.8/391.8 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, pyarrow, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 keras-3.7.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.29.1 pyarrow-18.1.0 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 werkzeug-3.1.3 wrapt-1.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (2.0.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m21.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.2/326.2 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.2 kiwisolver-1.4.7 matplotlib-3.9.3 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 13:16:24.806267: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-10 13:16:24.809440: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 13:16:24.814328: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-10 13:16:24.825484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733836584.843330      83 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733836584.848860      83 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-10 13:16:24.871074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n",
      "<class 'numpy.ndarray'>\n",
      "8\n",
      "[8]\n",
      "[[1 2]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) \n",
    "\n",
    "print(type(data))\n",
    "\n",
    "# xx = np.array([1,2,3,4,5])\n",
    "# xx = xx.reshape(5,1)\n",
    "# print(xx[3,0] + xx[3,0])\n",
    "# print(xx[3] + xx[3])\n",
    "\n",
    "# yy = []\n",
    "# yy.append(xx[0:2,0])\n",
    "# yy.append(xx[1:3,0])\n",
    "# print(np.array(yy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 13:58:55.154148: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 957ms/step - loss: 14.8193\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 913ms/step - loss: 0.2068\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 927ms/step - loss: 0.1677\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 938ms/step - loss: 0.1667\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 937ms/step - loss: 0.1262\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 932ms/step - loss: 0.2735\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 926ms/step - loss: 0.1383\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 929ms/step - loss: 0.1559\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 937ms/step - loss: 0.1149\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 943ms/step - loss: 0.1239\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 948ms/step - loss: 0.1343\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 934ms/step - loss: 0.0923\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 940ms/step - loss: 0.1075\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 925ms/step - loss: 0.1191\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 930ms/step - loss: 0.0893\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 939ms/step - loss: 0.1109\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 946ms/step - loss: 0.1891\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 929ms/step - loss: 0.0572\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 934ms/step - loss: 0.0637\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 0.0605\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1b44e45f10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 293ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 980ms/step - loss: 4.9993\n",
      "Epoch 2/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 951ms/step - loss: 1.4204\n",
      "Epoch 3/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 942ms/step - loss: 0.7723\n",
      "Epoch 4/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 956ms/step - loss: 0.3172\n",
      "Epoch 5/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 959ms/step - loss: 0.1506\n",
      "Epoch 6/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 949ms/step - loss: 0.0740\n",
      "Epoch 7/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 939ms/step - loss: 0.0504\n",
      "Epoch 8/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 944ms/step - loss: 0.0458\n",
      "Epoch 9/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 970ms/step - loss: 0.0339\n",
      "Epoch 10/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 943ms/step - loss: 0.0303\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Summary of the model \u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X, Y, epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mX_test\u001b[49m, y_test)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "drop1 = tf.keras.layers.Dropout(rate = 0.5)(flatten)\n",
    "outputs = tf.keras.layers.Dense(1)(drop1) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.fit(X, Y, epochs = 10, batch_size = 32)\n",
    "\n",
    "loss, accuracy = model.evaluate(X, Y)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y, epochs = 10, batch_size = 16)\n",
    "\n",
    "loss, accuracy = model.evaluate(X, Y)\n",
    "print(loss)\n",
    "print(accuracy)\n",
    "\n",
    "model.fit(X, Y, epochs = 10, batch_size = 64)\n",
    "\n",
    "loss, accuracy = model.evaluate(X, Y)\n",
    "print(loss)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 271ms/step - loss: 0.5484"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# outputs = tf.keras.layers.Dense(1, activation = 'tanh')(flatten) \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model = tf.keras.Model(inputs, outputs) \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# model.fit(X, Y, epochs = 10, batch_size = 64)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:481\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    480\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m--> 481\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(step, logs)\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputs = tf.keras.layers.Dense(1, activation = 'tanh')(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "model.fit(X, Y, epochs = 10, batch_size = 64)\n",
    "\n",
    "loss = model.evaluate(X, Y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "28ac4fd81c1d713f83dcd1cdf1d3383ad25ea92873288fe9e978e9a17b314709"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
